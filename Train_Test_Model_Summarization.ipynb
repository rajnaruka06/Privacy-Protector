{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, DataCollatorForSeq2Seq\n",
    "import evaluate\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"./Final_Data.xlsx\")\n",
    "df_train = df.sample(frac = 0.8, random_state = 42).reset_index(drop = True)\n",
    "df_test = df.drop(df_train.index).reset_index(drop = True)\n",
    "\n",
    "df_train = Dataset(pa.Table.from_pandas(df_train))\n",
    "df_test = Dataset(pa.Table.from_pandas(df_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [prefix + doc for doc in examples[\"Policy\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=1024, truncation=True, padding=True)\n",
    "    labels = tokenizer(text_target=examples[\"Summary\"], max_length=128, truncation=True)\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs\n",
    "\n",
    "\n",
    "tokenized_train = df_train.map(preprocess_function, batched=True)\n",
    "tokenized_test = df_test.map(preprocess_function, batched=True)\n",
    "\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=checkpoint)\n",
    "\n",
    "rouge = evaluate.load(\"rouge\")\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "\n",
    "    result = rouge.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "\n",
    "    return {k: round(v, 4) for k, v in result.items()}\n",
    "from transformers import AutoModelForSeq2SeqLM, Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(checkpoint)\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./Summary_Model\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=100,\n",
    "    predict_with_generate=True,\n",
    "    # fp16=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train,\n",
    "    eval_dataset=tokenized_test,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()\n",
    "model.save_pretrained(\"./Summary_Model_V1/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This privacy policy statement is positive because it tells you how the company uses your information to provide a personalised experience to you, including ads, and other purposes that they explain in detail below. The company uses your information to provide a personalised experience to you, including ads, along with other purposes that they explain in detail below. The company also uses manual review to access and review your information, and to use less information that's connected to individual users, in some cases we de-identify or aggregate information or anonymise it so that\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"./Summary_Model_V1/\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)\n",
    "tokenizer_checkpoint = \"t5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_checkpoint)\n",
    "prefix = \"summarize: \"\n",
    "\n",
    "def generate_summary(text):\n",
    "    inputs = prefix + text\n",
    "    input_ids = tokenizer.encode(inputs, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "    output = model.generate(input_ids=input_ids, max_length=128, num_beams=4, early_stopping=True)\n",
    "    summary = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return summary\n",
    "\n",
    "example_policy = \"\"\"We use Information we collect to provide a personalised experience to you, including ads, along with the other purposes that we explain in detail below.\n",
    "For some of these purposes, we use information  Acorss our products and Across our devices. The information that we use for these purposes is automatically processed by our systems. But in some cases, we also use  manual review to access and review your information.\n",
    "To use less information that's connected to individual users, in some cases we de-identify or aggregate information or anonymise it so that it no longer identifies you. We use this information in the same ways we use your information as described in this section.\"\"\"\n",
    "\n",
    "summary = generate_summary(example_policy)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Generated_Summary'] = df['Policy'].apply(generate_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"test_df.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
